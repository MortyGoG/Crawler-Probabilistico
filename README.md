# Crawler-Modelo Probabilistico
Este es el README para el proyecto Crawler-Probabilistico. Aquí encontrarás información sobre qué es este proyecto, cómo instalarlo y cómo utilizarlo.

Descripción
Crawler-Probabilistico es un proyecto que combina técnicas de web crawling (rastreo de la web) con el modelo Probabilistico. Su propósito es extraer datos de sitios web
y aplicar el modelo Probabilistico con el objetivo de obtener un resultado de documentos más cercanos a ser relevantes(similitudes) a una consulta dada.

Instalación
A continuación, se detallan los pasos para instalar y configurar el proyecto en tu entorno:

Requisitos previos:
Asegúrate de tener instalado Python en tu sistema. Este proyecto se basa en Python.

1. Clonar el repositorio:
```shell
git clone https://github.com/MortyGoG/Crawler-Probabilistico.git
cd Crawler-Probabilisitico
```

2. Instalar las dependencias:
Utiliza pip para instalar las bibliotecas necesarias:
```shell
pip install -r requirements.txt
```

3. Ejecuta desde tú entorno virtual para poder observar el proyecto

Nota:
Es necesario colocar documentos de texto en la carpeta "gatos/gatos/spiders/" o en su defecto quitar los comentarios del script(Web crawler ultimas lineas del codigo).
